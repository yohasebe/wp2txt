# frozen_string_literal: true

require "htmlentities"
require "json"

module Wp2txt
  # Data file paths
  MEDIAWIKI_DATA_PATH = File.join(__dir__, "data", "mediawiki_aliases.json")
  HTML_ENTITIES_PATH = File.join(__dir__, "data", "html_entities.json")
  WIKIPEDIA_ENTITIES_PATH = File.join(__dir__, "data", "wikipedia_entities.json")
  TEMPLATE_DATA_PATH = File.join(__dir__, "data", "template_aliases.json")

  # Load MediaWiki aliases from data file (generated by scripts/fetch_mediawiki_data.rb)
  def self.load_mediawiki_data
    return @mediawiki_data if @mediawiki_data

    if File.exist?(MEDIAWIKI_DATA_PATH)
      @mediawiki_data = JSON.parse(File.read(MEDIAWIKI_DATA_PATH))
    else
      # Fallback to minimal defaults if data file is missing
      @mediawiki_data = {
        "magic_words" => { "redirect" => ["REDIRECT"] },
        "namespaces" => { "category" => ["Category"], "file" => ["File", "Image"] }
      }
    end
    @mediawiki_data
  end

  # Load template aliases from data file (generated by scripts/fetch_template_data.rb)
  def self.load_template_data
    return @template_data if @template_data

    if File.exist?(TEMPLATE_DATA_PATH)
      @template_data = JSON.parse(File.read(TEMPLATE_DATA_PATH))
    else
      # Fallback to minimal defaults if data file is missing
      @template_data = {
        "remove_templates" => %w[reflist notelist main see\ also portal],
        "authority_control" => %w[authority\ control normdaten],
        "cleanup_remnants" => %w[clear clearleft clearright]
      }
    end
    @template_data
  end

  # Build regex pattern from template list (escapes special chars, joins with |)
  def self.build_template_regex(templates, options = {})
    return nil if templates.nil? || templates.empty?

    pattern = templates.map { |t| Regexp.escape(t) }.join("|")
    if options[:anchor_start]
      pattern = '\A\s*(?:' + pattern + ')'
    else
      pattern = '(?:' + pattern + ')'
    end
    if options[:require_pipe_or_end]
      pattern += '\s*(?:\||$)'
    end
    Regexp.new(pattern, Regexp::IGNORECASE)
  end

  # Load HTML entities from WHATWG data file (generated by scripts/fetch_html_entities.rb)
  def self.load_html_entities
    return @html_entities if @html_entities

    @html_entities = {}

    # Load WHATWG HTML entities
    if File.exist?(HTML_ENTITIES_PATH)
      data = JSON.parse(File.read(HTML_ENTITIES_PATH))
      @html_entities.merge!(data["entities"] || {})
    end

    # Load Wikipedia-specific entities (override/supplement WHATWG)
    if File.exist?(WIKIPEDIA_ENTITIES_PATH)
      data = JSON.parse(File.read(WIKIPEDIA_ENTITIES_PATH))
      @html_entities.merge!(data["entities"] || {})
    end

    @html_entities
  end

  # Build regex for extra entities not handled by HTMLEntities gem
  def self.build_extra_entities_regex
    entities = load_html_entities
    return nil if entities.empty?

    # Build regex pattern for all entity keys
    pattern = "(" + entities.keys.map { |k| Regexp.escape(k) }.join("|") + ")"
    Regexp.new(pattern)
  end
  ###################################################
  # variables to save resource for generating regexps
  # those with a trailing number 1 represent opening tag/markup
  # those with a trailing number 2 represent closing tag/markup
  # those without a trailing number contain both opening/closing tags/markups

  HTML_DECODER = HTMLEntities.new

  ENTITIES = ['&nbsp;', '&lt;', '&gt;', '&amp;', '&quot;'].zip([' ', '<', '>', '&', '"'])
  HTML_HASH = Hash[*ENTITIES.flatten]
  HTML_REGEX = Regexp.new("(" + HTML_HASH.keys.join("|") + ")")

  # Extra HTML entities loaded from JSON files (WHATWG + Wikipedia-specific)
  # These supplement the HTMLEntities gem which only covers ~250 basic entities
  # Data sources:
  #   - lib/wp2txt/data/html_entities.json (2000+ WHATWG entities)
  #   - lib/wp2txt/data/wikipedia_entities.json (Wikipedia-specific)
  EXTRA_ENTITIES = load_html_entities.freeze
  EXTRA_ENTITIES_REGEX = build_extra_entities_regex

  # Legacy alias for backward compatibility
  MATH_ENTITIES = EXTRA_ENTITIES
  MATH_ENTITIES_REGEX = EXTRA_ENTITIES_REGEX
  ML_TEMPLATE_ONSET_REGEX = Regexp.new('^\{\{[^\}]*$')
  ML_TEMPLATE_END_REGEX = Regexp.new('\}\}\s*$')
  # Match lines starting with [[ that don't end with ]] (handles inner links)
  ML_LINK_ONSET_REGEX = Regexp.new('^\[\[(?!.*\]\]\s*$).*$')
  ML_LINK_END_REGEX = Regexp.new('\]\]\s*$')
  ISOLATED_TEMPLATE_REGEX = Regexp.new('^\s*\{\{.+\}\}\s*$')
  ISOLATED_TAG_REGEX = Regexp.new('^\s*\<[^\<\>]+\>.+\<[^\<\>]+\>\s*$')
  IN_LINK_REGEX = Regexp.new('^\s*\[.*\]\s*$')
  IN_INPUTBOX_REGEX = Regexp.new('<inputbox>.*?<\/inputbox>')
  IN_INPUTBOX_REGEX1 = Regexp.new('<inputbox>')
  IN_INPUTBOX_REGEX2 = Regexp.new('<\/inputbox>')
  IN_SOURCE_REGEX = Regexp.new('<source.*?>.*?<\/source>')
  IN_SOURCE_REGEX1 = Regexp.new('<source.*?>')
  IN_SOURCE_REGEX2 = Regexp.new('<\/source>')
  IN_MATH_REGEX = Regexp.new('<math.*?>.*?<\/math>')
  IN_MATH_REGEX1 = Regexp.new('<math.*?>')
  IN_MATH_REGEX2 = Regexp.new('<\/math>')
  IN_HEADING_REGEX = Regexp.new('^=+.*?=+\s*$')
  IN_HTML_TABLE_REGEX = Regexp.new("<table.*?><\/table>")
  IN_HTML_TABLE_REGEX1 = Regexp.new('<table\b')
  IN_HTML_TABLE_REGEX2 = Regexp.new('<\/\s*table>')
  # HTML comments (can span multiple lines)
  HTML_COMMENT_REGEX = Regexp.new('<!--.*?-->', Regexp::MULTILINE)
  IN_TABLE_REGEX1 = Regexp.new('^\s*\{\|')
  IN_TABLE_REGEX2 = Regexp.new('^\|\}.*?$')
  IN_UNORDERED_REGEX = Regexp.new('^\*')
  IN_ORDERED_REGEX = Regexp.new('^\#')
  IN_PRE_REGEX = Regexp.new('^ ')
  IN_DEFINITION_REGEX = Regexp.new('^[\;\:]')
  BLANK_LINE_REGEX = Regexp.new('^\s*$')

  # Multilingual redirect keyword support
  # Data source: MediaWiki API (siteinfo) via scripts/fetch_mediawiki_data.rb
  REDIRECT_KEYWORDS = load_mediawiki_data.dig("magic_words", "redirect")&.join("|") || "REDIRECT"
  REDIRECT_REGEX = Regexp.new('[#＃](?:' + REDIRECT_KEYWORDS + ')\s*:?\s*\[\[([^\]]+)\]\]', Regexp::IGNORECASE)
  REMOVE_TAG_REGEX = Regexp.new("\<[^\<\>]*\>")

  # Legacy generic pattern for double-underscore directives
  # Note: Data-driven REMOVE_DIRECTIVES_REGEX is defined later (after DOUBLE_UNDERSCORE_MAGIC_REGEX)
  REMOVE_DIRECTIVES_REGEX_GENERIC = Regexp.new("\_\_[^\_]*\_\_")

  REMOVE_EMPHASIS_REGEX = Regexp.new('(' + Regexp.escape("''") + '+)(.+?)\1')
  CHRREF_TO_UTF_REGEX = Regexp.new('&#(x?)([0-9a-fA-F]+);')
  MNDASH_REGEX = Regexp.new('\{(mdash|ndash|–)\}')
  REMOVE_HR_REGEX = Regexp.new('^\s*\-{4,}\s*$')
  MAKE_REFERENCE_REGEX_A = Regexp.new('<br ?\/>', Regexp::IGNORECASE)
  MAKE_REFERENCE_REGEX_B = Regexp.new('<ref[^>]*\/>', Regexp::IGNORECASE)
  MAKE_REFERENCE_REGEX_C = Regexp.new('<ref[^>]*>', Regexp::IGNORECASE)
  MAKE_REFERENCE_REGEX_D = Regexp.new('<\/ref>', Regexp::IGNORECASE)
  FORMAT_REF_REGEX = Regexp.new('\[ref\](.*?)\[\/ref\]', Regexp::MULTILINE)
  HEADING_ONSET_REGEX = Regexp.new('^(\=+)\s+')
  HEADING_CODA_REGEX = Regexp.new('\s+(\=+)$')
  LIST_MARKS_REGEX = Regexp.new('\A[\*\#\;\:\ ]+')
  PRE_MARKS_REGEX = Regexp.new('\A\^\ ')
  DEF_MARKS_REGEX = Regexp.new('\A[\;\:\ ]+')
  ONSET_BAR_REGEX = Regexp.new('\A[^\|]+\z')

  # Multilingual category namespace support
  # Data source: MediaWiki API (siteinfo) via scripts/fetch_mediawiki_data.rb
  CATEGORY_NAMESPACES = load_mediawiki_data.dig("namespaces", "category")&.join("|") || "Category"

  # Multilingual file namespace support (for image/file links)
  FILE_NAMESPACES = load_mediawiki_data.dig("namespaces", "file")&.join("|") || "File|Image"
  FILE_NAMESPACES_REGEX = Regexp.new('\A\s*(?:' + FILE_NAMESPACES + ')\s*:', Regexp::IGNORECASE)

  # Multilingual category namespace support (for filtering out category links from body text)
  CATEGORY_NAMESPACE_REGEX = Regexp.new('\A\s*(?:' + CATEGORY_NAMESPACES + ')\s*:', Regexp::IGNORECASE)

  # Image parameters (multilingual) - used for filtering out non-caption parts of File/Image links
  # Combines: img_thumbnail, img_framed, img_frameless, img_border, img_right, img_left, img_center, img_none,
  # img_upright, img_baseline, img_sub, img_super, img_top, img_text_top, img_middle, img_bottom, img_text_bottom
  IMAGE_PARAM_KEYS = %w[img_thumbnail img_framed img_frameless img_border img_right img_left img_center img_none
                        img_upright img_baseline img_sub img_super img_top img_text_top img_middle img_bottom img_text_bottom].freeze
  IMAGE_PARAMS = IMAGE_PARAM_KEYS.flat_map { |k| load_mediawiki_data.dig("magic_words", k) || [] }.uniq.join("|")
  IMAGE_PARAMS_REGEX = IMAGE_PARAMS.empty? ? nil : Regexp.new('\A(' + IMAGE_PARAMS + ')\z', Regexp::IGNORECASE)

  # Cleanup regex patterns using dynamic file namespaces
  # For lines like "Image:file.jpg|thumb|...|caption" (gallery/imagemap remnants)
  CLEANUP_FILE_LINE_REGEX = Regexp.new('^(?:' + FILE_NAMESPACES + '):[^\n]+\|[^\n]+$', Regexp::IGNORECASE | Regexp::MULTILINE)
  # For incomplete File/Image links (opened but not closed)
  CLEANUP_FILE_INCOMPLETE_REGEX = Regexp.new('\[\[(?:' + FILE_NAMESPACES + '):[^\]]*\|?\s*$', Regexp::IGNORECASE | Regexp::MULTILINE)

  # Category regex - captures category name without sortkey
  # [[Category:Name|sortkey]] -> captures only "Name" (not "Name|sortkey")
  # The (?:[^\|\]\}]*) captures the category name up to | or ] or }
  CATEGORY_REGEX = Regexp.new('[\{\[\|\b](?:' + CATEGORY_NAMESPACES + ')\s*:([^\|\]\}]+)[\|\]\}]', Regexp::IGNORECASE)

  ESCAPE_NOWIKI_REGEX = Regexp.new('<nowiki>(.*?)<\/nowiki>', Regexp::MULTILINE)
  UNESCAPE_NOWIKI_REGEX = Regexp.new('<nowiki\-(\d+?)>')

  REMOVE_ISOLATED_REGEX = Regexp.new('^\s*\{\{(.*?)\}\}\s*$')
  REMOVE_INLINE_REGEX = Regexp.new('\{\{(.*?)\}\}')

  # Note: TYPE_CODE_REGEX removed (was unused dead code)
  # Template type detection is now handled by data-driven patterns in template_aliases.json

  SINGLE_SQUARE_BRACKET_REGEX = Regexp.new("(#{Regexp.escape("[")}|#{Regexp.escape("]")})", Regexp::MULTILINE)
  DOUBLE_SQUARE_BRACKET_REGEX = Regexp.new("(#{Regexp.escape("[[")}|#{Regexp.escape("]]")})", Regexp::MULTILINE)
  SINGLE_CURLY_BRACKET_REGEX = Regexp.new("(#{Regexp.escape("{")}|#{Regexp.escape("}")})", Regexp::MULTILINE)
  DOUBLE_CURLY_BRACKET_REGEX = Regexp.new("(#{Regexp.escape("{{")}|#{Regexp.escape("}}")})", Regexp::MULTILINE)
  CURLY_SQUARE_BRACKET_REGEX = Regexp.new("(#{Regexp.escape("{|")}|#{Regexp.escape("|}")})", Regexp::MULTILINE)

  SELF_CLOSING_TAG_REGEX = Regexp.new('<[^<>]+/>')
  COMPLEX_REGEX_01 = Regexp.new('\<\<([^<>]++)\>\>\s?')
  COMPLEX_REGEX_02 = Regexp.new('\[\[File\:((?:[^\[\]]++|\[\[\g<1>\]\])++)\]\]', Regexp::MULTILINE | Regexp::IGNORECASE)
  COMPLEX_REGEX_03 = Regexp.new('^\[\[((?:[^\[\]]++|\[\[\g<1>\]\])++)^\]\]', Regexp::MULTILINE)
  COMPLEX_REGEX_04 = Regexp.new('\{\{(?:infobox|efn|sfn|unreliable source|refn|reflist|col(?:umns)?\-list|div col|no col|bar box|formatnum\:|col\||see also\||r\||#)((?:[^{}]++|\{\{\g<1>\}\})++)\}\}', Regexp::MULTILINE | Regexp::IGNORECASE)
  COMPLEX_REGEX_05 = Regexp.new('\{\{[^{}]+?\n\|((?:[^{}]++|\{\{\g<1>\}\})++)\}\}', Regexp::MULTILINE | Regexp::IGNORECASE)

  CLEANUP_REGEX_01 = Regexp.new('\[ref\]\s*\[\/ref\]', Regexp::MULTILINE)
  CLEANUP_REGEX_02 = Regexp.new('^File:.+$')
  CLEANUP_REGEX_03 = Regexp.new('^\|.*$')
  CLEANUP_REGEX_04 = Regexp.new('\{\{.*$')
  CLEANUP_REGEX_05 = Regexp.new('^.*\}\}')
  CLEANUP_REGEX_06 = Regexp.new('\{\|.*$')
  CLEANUP_REGEX_07 = Regexp.new('^.*\|\}')
  CLEANUP_REGEX_08 = Regexp.new('\n\n\n+', Regexp::MULTILINE)

  # =========================================================================
  # Multilingual cleanup patterns (language-agnostic)
  # =========================================================================

  # MediaWiki magic words (universal across all wikis)
  # DEFAULTSORT, DISPLAYTITLE, etc. - loaded from mediawiki_aliases.json for multilingual support
  DEFAULTSORT_KEYWORDS = load_mediawiki_data.dig("magic_words", "defaultsort")&.join("|") || "DEFAULTSORT"
  DISPLAYTITLE_KEYWORDS = load_mediawiki_data.dig("magic_words", "displaytitle")&.join("|") || "DISPLAYTITLE"

  # Match bare magic words on their own line: DEFAULTSORT:value or デフォルトソート:value
  MAGIC_WORD_LINE_REGEX = Regexp.new('^(?:' + DEFAULTSORT_KEYWORDS + '|' + DISPLAYTITLE_KEYWORDS + ')[^\n]*$', Regexp::IGNORECASE)

  # Match magic word template format: {{DEFAULTSORT:value}} or {{デフォルトソート:value}}
  MAGIC_WORD_TEMPLATE_REGEX = Regexp.new('\{\{\s*(?:' + DEFAULTSORT_KEYWORDS + '|' + DISPLAYTITLE_KEYWORDS + ')[^\}]*\}\}', Regexp::IGNORECASE)

  # Double-underscore magic words: __NOTOC__, __TOC__, __FORCETOC__, __NOEDITSECTION__, etc.
  # Data source: MediaWiki API (siteinfo) via scripts/fetch_mediawiki_data.rb
  # Contains 1198 multilingual aliases for behavior switches
  DOUBLE_UNDERSCORE_PATTERNS = load_mediawiki_data.dig("magic_words", "double_underscore") || []
  DOUBLE_UNDERSCORE_MAGIC_REGEX = if DOUBLE_UNDERSCORE_PATTERNS.empty?
    Regexp.new('__[A-Z]+__')  # Fallback to basic pattern
  else
    # Build alternation pattern from actual magic word aliases
    pattern = DOUBLE_UNDERSCORE_PATTERNS.map { |p| Regexp.escape(p) }.join("|")
    Regexp.new('(?:' + pattern + ')', Regexp::IGNORECASE)
  end

  # Data-driven pattern for removing double-underscore behavior switches from text
  # Uses the comprehensive multilingual magic word list (1198 aliases)
  # Falls back to generic pattern if data file is empty
  REMOVE_DIRECTIVES_REGEX = DOUBLE_UNDERSCORE_PATTERNS.empty? ?
    REMOVE_DIRECTIVES_REGEX_GENERIC :
    DOUBLE_UNDERSCORE_MAGIC_REGEX

  # Interwiki links: :en:Article, :fr:Article, :de:Article, etc.
  # Removes the prefix but keeps the article name
  INTERWIKI_PREFIX_REGEX = Regexp.new(':([a-z]{2,3}):(?=[^\s\]]+)')

  # Authority control and metadata templates (standalone lines)
  # These are template names that appear alone on a line after processing
  # Data source: template_aliases.json (authority_control category)
  AUTHORITY_CONTROL_TEMPLATES = load_template_data["authority_control"] || []
  AUTHORITY_CONTROL_REGEX = if AUTHORITY_CONTROL_TEMPLATES.empty?
    # Fallback to basic pattern
    Regexp.new(
      '^\s*(Normdaten|Authority\s*control|Persondata|VIAF|LCCN|GND)\s*$',
      Regexp::MULTILINE | Regexp::IGNORECASE
    )
  else
    pattern = AUTHORITY_CONTROL_TEMPLATES.map { |t| Regexp.escape(t) }.join("|")
    Regexp.new('^\s*(' + pattern + ')\s*$', Regexp::MULTILINE | Regexp::IGNORECASE)
  end

  # Cleanup remnants - template names that appear as artifacts after processing
  # Data source: template_aliases.json (cleanup_remnants category)
  CLEANUP_REMNANTS_TEMPLATES = load_template_data["cleanup_remnants"] || []
  CLEANUP_REMNANTS_REGEX = if CLEANUP_REMNANTS_TEMPLATES.empty?
    # Fallback to basic pattern
    Regexp.new('^\s*(Clear|Clearleft|Clearright|notelist\d*)\s*$', Regexp::MULTILINE | Regexp::IGNORECASE)
  else
    pattern = CLEANUP_REMNANTS_TEMPLATES.map { |t| Regexp.escape(t) }.join("|")
    # Also match notelist with numbers (notelist2, notelist3, etc.)
    pattern += '|notelist\d+'
    Regexp.new('^\s*(' + pattern + ')\s*$', Regexp::MULTILINE | Regexp::IGNORECASE)
  end

  # Category line patterns for all Wikipedia languages
  # Loaded from mediawiki_aliases.json for complete multilingual support (230+ languages)
  # Note: Must NOT match "CATEGORIES:" (our summary line)
  CATEGORY_LINE_REGEX = Regexp.new(
    '^\s*\*?\s*(?!CATEGORIES)(?:' + CATEGORY_NAMESPACES + '):[^\n]+$',
    Regexp::MULTILINE | Regexp::IGNORECASE
  )

  # Wikimedia sister project markers (standalone lines)
  # Data source: MediaWiki API (siteinfo interwikimap) via scripts/fetch_mediawiki_data.rb
  # Contains 546 sister project prefixes from all Wikipedia language editions
  SISTER_PROJECTS = load_mediawiki_data.dig("interwiki", "sister_projects") || []
  # Filter to only keep known Wikimedia project names (not language codes)
  WIKIMEDIA_PROJECT_NAMES = %w[
    wikibooks wikiversity wikisource wikiquote wikinews wiktionary
    wikivoyage wikispecies wikidata commons meta mediawiki
    mediawikiwiki species oldwikisource wikifunctions school
  ].freeze
  WIKIMEDIA_PROJECT_REGEX = begin
    # Combine known project names with any from data
    projects_from_data = SISTER_PROJECTS.select { |p| WIKIMEDIA_PROJECT_NAMES.include?(p.downcase) }
    # Always include all known project names (ensures complete coverage)
    all_projects = (WIKIMEDIA_PROJECT_NAMES + projects_from_data).uniq
    # Add common variations
    pattern_parts = all_projects.map { |p| Regexp.escape(p) }
    pattern_parts << 'Wikimedia\s*Commons'  # Common alternate form
    pattern_parts << 'Commons\s*cat(?:egory)?'  # Commons category template
    Regexp.new(
      '^\s*(' + pattern_parts.join("|") + ')(?::|$)',
      Regexp::MULTILINE | Regexp::IGNORECASE
    )
  end

  # Lines that are just a single asterisk (list marker without content)
  LONE_ASTERISK_REGEX = Regexp.new('^\s*\*\s*$', Regexp::MULTILINE)

  # =========================================================================
  # Non-article namespace prefixes (for validation filtering)
  # =========================================================================
  # These are namespaces that should be excluded from article validation
  # as they contain templates, portals, help pages, etc. not encyclopedia content
  #
  # Data source: MediaWiki API (siteinfo) via scripts/fetch_mediawiki_data.rb
  # Contains 6083 namespace aliases from 351 Wikipedia language editions
  NON_ARTICLE_NAMESPACES = (load_mediawiki_data.dig("namespaces", "non_article") || []).freeze

  # Build regex for matching non-article titles
  # Matches "Namespace:Title" where Namespace is in the list
  NON_ARTICLE_NAMESPACE_REGEX = if NON_ARTICLE_NAMESPACES.empty?
    # Fallback to basic English namespaces
    Regexp.new(
      '\A\s*(Wikipedia|Template|Portal|Help|Category|File|Image|User|Talk|Module|Draft|MediaWiki)\s*:',
      Regexp::IGNORECASE
    )
  else
    Regexp.new(
      '\A\s*(' + NON_ARTICLE_NAMESPACES.map { |ns| Regexp.escape(ns) }.join("|") + ')\s*:',
      Regexp::IGNORECASE
    )
  end

  # Helper method to check if a title is an article page (not a special namespace)
  def self.article_page?(title)
    return true if title.nil? || title.empty?
    !(title =~ NON_ARTICLE_NAMESPACE_REGEX)
  end
end
